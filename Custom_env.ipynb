{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gymlibrary.dev/content/environment_creation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __init__ method of our environment will accept the integer size, that determines the size of the square grid. We will set up some variables for rendering and define self.observation_space and self.action_space. In our case, observations should provide information about the location of the agent and target on the 2-dimensional grid. We will choose to represent observations in the form of a dictionaries with keys \"agent\" and \"target\". An observation may look like {\"agent\": array([1, 0]), \"target\": array([0, 3])}. Since we have 4 actions in our environment (“right”, “up”, “left”, “down”), we will use Discrete(4) as an action space. Here is the declaration of GridWorldEnv and the implementation of __init__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\":4}\n",
    "\n",
    "    def __init__(self, render_mode = None, size = 5):\n",
    "        self.size = size #The size of the square grid\n",
    "        self.window_size = 512 #The size of the PyGame window\n",
    "\n",
    "        # Observations are dictionaries with the agent's and the target's location\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"agent\": spaces.Box(0, size-1, shape=(2,), dtype=int),\n",
    "                \"target\": spaces.Box(0, size-1, shape=(2,), dtype=int),\n",
    "            }\n",
    "        )\n",
    "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        #The following dictionary maps abstract actions from \"self.actions_space\" to the direction we will walk in if that action is taken\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1, 0]),\n",
    "            1: np.array([0, 1]),\n",
    "            2: np.array([-1, 0]),\n",
    "            3: np.array([0, -1]),\n",
    "        }\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        #If human-rendering is used, 'self window' will be a reference to the window that we draw to self.clock will be a clock that is used to ensure that the environment is rendered at the correct framerate in human-mode. They will remain 'None' until human-mode is used for the first-time.\n",
    "\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return{\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "    \n",
    "    def _get_info(self):\n",
    "        return{\"distance\": np.linalg.norm(self._agent_location - self._target_location, ord=1)}\n",
    "    \n",
    "    def reset(self, seed = None, options=None):\n",
    "        #We need the following line to seed self.np_random\n",
    "        super().reset(seed = seed)\n",
    "\n",
    "        #Choose the agent's location uniformly at random\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        #We will sample the target's location randomly until it does not coincide with the agent's location\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(\n",
    "                0, self.size, size = 2, dtype = int\n",
    "            )\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        #Map the action (element of {0,1,2,3}) to the direction we walk in\n",
    "        direction = self._action_to_direction[action]\n",
    "        #We use 'np.clip' to make sure we do not leave the grid\n",
    "        self._agent_location = np.clip(\n",
    "            self._agent_location + direction, 0, self.size - 1\n",
    "        )\n",
    "\n",
    "        #An episode is done if the agent has reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "        reward = 1 if terminated else 0\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        \n",
    "        return observation, reward, terminated, False, info\n",
    "    \n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
