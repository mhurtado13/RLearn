{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build an agent to give us the best shower possible \n",
    "- Randomly temperature\n",
    "- Goal: Maintain temperature between 37 and 39 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3) #Actions types val agent can do\n",
    "        self.observation_space = Box(low=0, high=100, shape=(1,)) #Observation space\n",
    "        self.state = 38 + random.randint(-3,3) #State = Current temperature\n",
    "        self.shower_length = 60 #Shower time\n",
    "    def step(self, action):\n",
    "        self.state += action-1 #Apply impact of the action to the state\n",
    "        self.shower_length -= 1 #Decrease shower time \n",
    "\n",
    "        #Calculate reward\n",
    "        if self.state >= 37 and self.state <= 39:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "\n",
    "        #Finish episode\n",
    "        if self.shower_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        info = {}\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def render(self): #Implement visualization\n",
    "        pass\n",
    "    def reset(self):\n",
    "        self.state = np.array([38+random.randint(-3,3)]).astype(float) #Set initial temperature\n",
    "        self.shower_length = 60 #Reset shower length\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.435839], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-60\n",
      "Episode:2 Score:-4\n",
      "Episode:3 Score:-60\n",
      "Episode:4 Score:-40\n",
      "Episode:5 Score:-38\n"
     ]
    }
   ],
   "source": [
    "episodes = 5 #Try the environment 5 times\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset() #Initial set of observations\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render() #View the graphical representation of env\n",
    "        action = env.action_space.sample() #Random selection of an action\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo.hurtado/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -19.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 3847     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -25.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2569       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00784824 |\n",
      "|    clip_fraction        | 0.0451     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | -2.46e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.2       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00263   |\n",
      "|    value_loss           | 67.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -29.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2339        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010754477 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -7.27e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -29.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2250       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00395452 |\n",
      "|    clip_fraction        | 0.0449     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | -6.44e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.7       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0021    |\n",
      "|    value_loss           | 69.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -23.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1899        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010796819 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -1.67e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -19.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1905         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018129346 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -1.07e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 0.000651     |\n",
      "|    value_loss           | 83.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1918        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015146314 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 9e-05       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -22.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1928        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006331319 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | -0.000168   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -20.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1848       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00872428 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.985     |\n",
      "|    explained_variance   | -0.00295   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 44.3       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00896   |\n",
      "|    value_loss           | 81.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -19.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1863        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001556517 |\n",
      "|    clip_fraction        | 0.00654     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.958      |\n",
      "|    explained_variance   | -0.00115    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.000935   |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -22.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1875        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004813775 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | -7.39e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -21.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1871         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038289756 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.914       |\n",
      "|    explained_variance   | 0.000176     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43.1         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000605    |\n",
      "|    value_loss           | 70.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -21.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1865         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042630117 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | -0.000724    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.6         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 81.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -16.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1787        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004420828 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.000585    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000724   |\n",
      "|    value_loss           | 89.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -14.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1720        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003638495 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | -0.00182    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000585   |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -11.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1736         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028536052 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.791       |\n",
      "|    explained_variance   | -0.000238    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 81           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -10.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1750         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020584667 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.791       |\n",
      "|    explained_variance   | -0.000271    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 85.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -9.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1762         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019522681 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.786       |\n",
      "|    explained_variance   | 0.00544      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 78           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -6.44        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1773         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033104634 |\n",
      "|    clip_fraction        | 0.0739       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.776       |\n",
      "|    explained_variance   | -0.0268      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 79.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -6.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1779         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040796567 |\n",
      "|    clip_fraction        | 0.081        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.769       |\n",
      "|    explained_variance   | -0.000108    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36           |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | 0.00143      |\n",
      "|    value_loss           | 80.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x73c65462ae00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.0, 58.787753826796276)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
